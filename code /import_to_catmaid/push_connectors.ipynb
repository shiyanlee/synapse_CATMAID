{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd89959-5e46-4fa5-ac66-4bac6cad1d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  : Global CATMAID instance set. Caching is ON. (pymaid)\n"
     ]
    }
   ],
   "source": [
    "import pymaid\n",
    "url = \"https://neurophyla.mrc-lmb.cam.ac.uk/catmaid/fibsem/#\"\n",
    "token = \"4fe0c0572331265c61bf6ba4acd77cbed9792276\"\n",
    "name = \"SYLee\"\n",
    "password = \"Blue Skies\"\n",
    "project_id = 18\n",
    "rm = pymaid.CatmaidInstance(url, token, name, password, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6b50cf71-46cc-49ac-ba97-26bb28914fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import pandas as pd \n",
    "fp_df=pd.read_csv('~/Documents/CATMAID/pymaid/8_falsepositive/octo_cube3_same_preid_128/false_positives.csv')\n",
    "gt_df=pd.read_csv('~/Documents/CATMAID/pymaid/8_falsepositive/octo_cube3_same_preid_128/matched_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "41305a65-144c-47c9-aa8b-b00cc7abbbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pred_pre_x', 'pred_pre_y', 'pred_pre_z', 'pred_post_x', 'pred_post_y',\n",
      "       'pred_post_z', 'gt_pre_x', 'gt_pre_y', 'gt_pre_z', 'gt_post_x',\n",
      "       'gt_post_y', 'gt_post_z', 'distance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(gt_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16f4f0fb-9de1-4c52-90da-86c7788f0c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x_min', 'x_max', 'y_min', 'y_max', 'z_min', 'z_max', 'x_distance',\n",
      "       'y_distance', 'z_distance', 'number of points inside'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bbox3=pd.read_csv('synapsescube3_bbox.csv')\n",
    "print(bbox3.columns)\n",
    "#bbox in pixels \n",
    "x_max = int(bbox3['x_max'].iloc[0])\n",
    "y_min = int(bbox3['y_min'].iloc[0])\n",
    "z_min = int(bbox3['z_min'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ff2cd223-b47f-4960-8a6a-174c1c442c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_coords(coords):\n",
    "    coords = list(coords)\n",
    "    original_x = (x_max - (coords[0]/ 8)) * 8\n",
    "    original_y = (coords[1] / 8 + y_min) * 8\n",
    "    original_z = (coords[2] / 8 + z_min) * 8\n",
    "    return (original_x,original_y,original_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40186adc-76a5-40f3-93ea-5f27c4649b2a",
   "metadata": {},
   "source": [
    "### ADD NODE(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "003e74bd-1c66-479a-ad29-d07e3bca3a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to CSV successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "for index, row in fp_df.iterrows():\n",
    "    post_x, post_y, post_z = row[\"pred_post_x\"], row[\"pred_post_y\"], row[\"pred_post_z\"]\n",
    "    post_coords = (post_x, post_y, post_z)\n",
    "    \n",
    "    # Transform the coordinates\n",
    "    post_coords_new = reverse_coords(post_coords)\n",
    "    \n",
    "    # Send the request and get response\n",
    "    response = pymaid.add_node(post_coords_new, parent_id=None, radius=-1, confidence=5)\n",
    "\n",
    "    # Store response data in a dictionary\n",
    "    response_data = {\n",
    "        \"index\": index,\n",
    "        \"pred_post_x\": post_x,\n",
    "        \"pred_post_y\": post_y,\n",
    "        \"pred_post_z\": post_z,\n",
    "        \"post_x_new\": post_coords_new[0],\n",
    "        \"post_y_new\": post_coords_new[1],\n",
    "        \"post_z_new\": post_coords_new[2],\n",
    "        \"treenode_id\": response.get(\"treenode_id\"),\n",
    "        \"skeleton_id\": response.get(\"skeleton_id\"),\n",
    "        \"edition_time\": response.get(\"edition_time\"),\n",
    "        \"parent_edition_time\": response.get(\"parent_edition_time\"),\n",
    "        \"created_links\": response.get(\"created_links\"),\n",
    "    }\n",
    "\n",
    "    # Append to results list\n",
    "    results.append(response_data)\n",
    "\n",
    "# Convert results to a new DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to a new CSV file\n",
    "results_df.to_csv('~/Documents/CATMAID/pymaid/8_falsepositive/octo_cube3_same_preid_128/matched_pairs_with_nodes.csv', index=False)\n",
    "\n",
    "print(\"Results saved to CSV successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a173324-3411-4eeb-b262-ebff5ff79b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyid=results_df['skeleton_id'].tolist()\n",
    "pymaid.add_annotations(bodyid, 'pushed false positives synapses', remote_instance=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac0bae27-aaf5-4115-878b-c7406a9a47f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating connectors: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating connectors: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating connectors: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating connectors: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating connectors: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to CSV successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []  # Store results\n",
    "\n",
    "for index, row in fp_df.iterrows():\n",
    "    # Extract coordinates for pre and post\n",
    "    pre_x, pre_y, pre_z = row[\"pred_pre_x\"], row[\"pred_pre_y\"], row[\"pred_pre_z\"]\n",
    "    post_x, post_y, post_z = row[\"pred_post_x\"], row[\"pred_post_y\"], row[\"pred_post_z\"]\n",
    "    \n",
    "    pre_conn = (pre_x, pre_y, pre_z)\n",
    "    post_conn = (post_x, post_y, post_z)\n",
    "    \n",
    "    # Transform pre-connection coordinates\n",
    "    pre_conn_new = reverse_coords(pre_conn)\n",
    "    pre_conn_new_list = list(pre_conn_new)\n",
    "\n",
    "    # Push to CATMAID\n",
    "    response = pymaid.add_connector(pre_conn_new_list, remote_instance=None)\n",
    "\n",
    "    # Ensure response is a non-empty list before accessing it\n",
    "    if response and isinstance(response, list):\n",
    "        response_dict = response[0]  # Extract the first dictionary\n",
    "\n",
    "        # Store response data\n",
    "        response_data = {\n",
    "            \"index\": index,\n",
    "            \"pred_pre_x\": pre_x,\n",
    "            \"pred_pre_y\": pre_y,\n",
    "            \"pred_pre_z\": pre_z,\n",
    "            \"pred_post_x\": post_x,  # Include post-synaptic coordinates\n",
    "            \"pred_post_y\": post_y,\n",
    "            \"pred_post_z\": post_z,\n",
    "            \"pre_x_new\": pre_conn_new_list[0],\n",
    "            \"pre_y_new\": pre_conn_new_list[1],\n",
    "            \"pre_z_new\": pre_conn_new_list[2],\n",
    "            \"connector_id\": response_dict.get(\"connector_id\"),\n",
    "            \"connector_edition_time\": response_dict.get(\"connector_edition_time\"),\n",
    "            \"created_links\": response_dict.get(\"created_links\"),\n",
    "        }\n",
    "\n",
    "        # Append to results list\n",
    "        results.append(response_data)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv('~/Documents/CATMAID/pymaid/8_falsepositive/octo_cube3_same_preid_128/fp_connectors_push.csv', index=False)\n",
    "\n",
    "print(\"Results saved to CSV successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149e06a9-b478-4a7d-8857-447d10737d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pred_post_x', 'pred_post_y', 'pred_post_z', 'post_x_new', 'post_y_new',\n",
      "       'post_z_new', 'treenode_id', 'skeleton_id', 'index_y', 'pred_pre_x',\n",
      "       'pred_pre_y', 'pred_pre_z', 'pre_x_new', 'pre_y_new', 'pre_z_new',\n",
      "       'connector_id'],\n",
      "      dtype='object')\n",
      "Merged file saved as 'combination.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "node = pd.read_csv(\"~/Documents/CATMAID/pymaid/8_falsepositive/octo_cube3_same_preid_128/matched_pairs_with_nodes.csv\")  # Replace with your actual file path\n",
    "connectors = pd.read_csv('~/Documents/CATMAID/pymaid/8_falsepositive/octo_cube3_same_preid_128/fp_connectors_push.csv')  # Replace with your actual file path\n",
    "\n",
    "# Merge based on the overlapping columns\n",
    "merged_df = pd.merge(node, connectors, on=[\"pred_post_x\", \"pred_post_y\", \"pred_post_z\"], how=\"outer\")\n",
    "\n",
    "\n",
    "df = merged_df.drop(columns=[\n",
    "    'index_x','edition_time', 'parent_edition_time',\n",
    "    'created_links_x','connector_edition_time', 'created_links_y'])\n",
    "\n",
    "print(df.columns)\n",
    "df.to_csv(\"combination.csv\", index=False)\n",
    "\n",
    "print(\"Merged file saved as 'combination.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a4fa2-9ee5-4413-a808-75ecbb10a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract necessary columns and form a list of tuples\n",
    "links = list(df[['treenode_id', 'connector_id']].itertuples(index=False, name=None))\n",
    "\n",
    "# Add 'postsynaptic_to' as the third element in each tuple\n",
    "links = [(node_id, conn_id, 'postsynaptic_to') for node_id, conn_id in links]\n",
    "\n",
    "response = pymaid.link_connector(links)\n",
    "\n",
    "# # Print response from the server\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f60b06cd-c255-4100-81e3-9566e7f5581b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368, 912, 184) ([1368, 912, 184], 0    48768.0\n",
      "Name: x_max, dtype: float64, 0    26944.0\n",
      "Name: y_min, dtype: float64, 0    59896.0\n",
      "Name: z_min, dtype: float64)\n",
      "[1336, 968, 112] ([1336, 968, 112], 0    48800.0\n",
      "Name: x_max, dtype: float64, 0    27000.0\n",
      "Name: y_min, dtype: float64, 0    59824.0\n",
      "Name: z_min, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "for index , row in fp_df.iterrows():\n",
    "    post_x, post_y, post_z = row[\"pred_post_x\"],row[\"pred_post_y\"],row[\"pred_post_z\"]\n",
    "    post_coords = (post_x, post_y, post_z)\n",
    "    #pymaid.add_node((post_x, post_y, post_z), remote_instance=rm)\n",
    "    post_coords_new = reverse_coords(post_coords)\n",
    "    print(post_coords, post_coords_new)\n",
    "    connectors = row[[\"pred_pre_x\", \"pred_pre_y\", \"pred_pre_z\"]].tolist()\n",
    "    conn_coords_new = reverse_coords(connectors)\n",
    "\n",
    "    print(connectors, conn_coords_new)\n",
    "    break\n",
    "    #pymaid.add_connector()\n",
    "    \n",
    "#pymaid.add_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02afb624-935e-4eec-8560-6afa137aa6ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1140428030.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[57], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "for index , row in gt_df.iterrows():\n",
    "    post_x, post_y, post_z = row[\"gt_post_x\"],row[\"gt_post_y\"],row[\"gt_post_z\"]\n",
    "    post_coords = (post_x, post_y, post_z)\n",
    "    post_coords_new = reverse_coords(post_coords)\n",
    "    pymaid.add_node((post_x, post_y, post_z), remote_instance=rm)\n",
    "    # # print(post_coords, post_coords_new)\n",
    "    # connectors = row[[\"gt_pre_x\", \"gt_pre_y\", \"gt_pre_z\"]].tolist()\n",
    "    # conn_coords_new = reverse_coords(connectors)\n",
    "\n",
    "    # print(connectors, conn_coords_new)\n",
    "    # if index > 2:\n",
    "    break\n",
    "    #pymaid.add_connector()\n",
    "    \n",
    "#pymaid.add_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9209b9-da8d-4487-bba9-d555d01ac083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV containing skeleton IDs\n",
    "post_push = pd.read_csv('~/Documents/CATMAID/pymaid/8_falsepositive/octo_cube3_same_preid_128/matched_pairs_with_nodes.csv')\n",
    "\n",
    "# Loop through each row instead of using a list\n",
    "for index, row in post_push.iterrows():\n",
    "    skeleton_id = row[\"skeleton_id\"]  # Extract skeleton ID\n",
    "    \n",
    "    if pd.isna(skeleton_id):  # Skip if skeleton_id is missing (NaN)\n",
    "        print(f\"Skipping row {index}: No skeleton_id found\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Attempt to delete neuron\n",
    "        response = pymaid.delete_neuron(int(skeleton_id), no_prompt=True, remote_instance=None)\n",
    "        print(f\"Deleted skeleton_id {skeleton_id}: {response}\")\n",
    "    except Exception as e:\n",
    "        # If deletion fails, print error and continue with the next row\n",
    "        print(f\"Failed to delete skeleton_id {skeleton_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4db5c-7976-4ea9-9271-ab3454732385",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron=pd.read_csv('combination.csv')\n",
    "skids=neuron['skeleton_id'].tolist()\n",
    "skids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181c904d-a839-4647-bc65-da819a7b8a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  : Cached data used. Use `pymaid.clear_cache()` to clear. (pymaid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymaid\n",
    "import time\n",
    "\n",
    "# Read the CSV\n",
    "neuron = pd.read_csv('combination.csv')\n",
    "\n",
    "# Extract skeleton IDs\n",
    "skids = neuron['skeleton_id'].tolist()\n",
    "\n",
    "# Function to split list into chunks of size 250\n",
    "def chunk_list(lst, chunk_size=250):\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i:i + chunk_size]\n",
    "\n",
    "# Dictionary to store annotations\n",
    "annotations_dict = {}\n",
    "\n",
    "# Process in batches of 250\n",
    "for batch in chunk_list(skids, 250):\n",
    "    try:\n",
    "        annotations = pymaid.get_annotations(batch)  # Fetch annotations\n",
    "        annotations_dict.update(annotations)  # Merge results\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching annotations for batch {batch}: {e}\")\n",
    "    time.sleep(1)  # Avoid overloading the server\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "annotations_df = pd.DataFrame(list(annotations_dict.items()), columns=['skeleton_id', 'annotations'])\n",
    "\n",
    "# Ensure skeleton_id type matches the original CSV\n",
    "annotations_df['skeleton_id'] = annotations_df['skeleton_id'].astype(neuron['skeleton_id'].dtype)\n",
    "\n",
    "# Expand the list of annotations into separate columns\n",
    "annotations_expanded = annotations_df['annotations'].apply(pd.Series)\n",
    "\n",
    "# Rename columns dynamically (Annotation_1, Annotation_2, etc.)\n",
    "annotations_expanded.columns = [f'Annotation_{i+1}' for i in range(annotations_expanded.shape[1])]\n",
    "\n",
    "# Combine skeleton_id with expanded annotations\n",
    "annotations_df = pd.concat([annotations_df[['skeleton_id']], annotations_expanded], axis=1)\n",
    "\n",
    "# Merge back with the original CSV\n",
    "neuron = neuron.merge(annotations_df, on='skeleton_id', how='left')\n",
    "\n",
    "# Save the updated DataFrame\n",
    "neuron.to_csv('combination_updated.csv', index=False)\n",
    "\n",
    "print(\"CSV updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c62f4-70e6-4a58-aea8-1e54bab259c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d82198-bf58-45b8-b22c-fa7e8a3cf32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
